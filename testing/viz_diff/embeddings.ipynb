{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from openai import OpenAI\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the OpenAI API key from the environment variable\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "# Get the embeddings for the two input texts\n",
    "response1 = client.embeddings.create(input=\"Joanne is a girl\", model=\"text-embedding-3-small\")\n",
    "response2 = client.embeddings.create(input=\"Joanne is a good girl\", model=\"text-embedding-3-small\")\n",
    "\n",
    "# Extract the embeddings as numpy arrays\n",
    "embedding_1 = np.array(response1.data[0].embedding)\n",
    "embedding_2 = np.array(response2.data[0].embedding)\n",
    "\n",
    "# Compute the differences between the embeddings\n",
    "embedding_diff = embedding_1 - embedding_2\n",
    "\n",
    "# Step 1: Compute the dot product\n",
    "dot_product = np.dot(embedding_1, embedding_2)\n",
    "\n",
    "# Step 2: Compute norms (magnitudes)\n",
    "norm_1 = np.linalg.norm(embedding_1)\n",
    "norm_2 = np.linalg.norm(embedding_2)\n",
    "\n",
    "# Step 3: Compute cosine similarity\n",
    "cosine_similarity = dot_product / (norm_1 * norm_2)\n",
    "\n",
    "print(f\"Cosine Similarity: {cosine_similarity}\")\n",
    "\n",
    "# Step 4: Plot the differences with red-green coloring (red for negative, green for positive)\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Create a color map: red for negative and green for positive\n",
    "colors = ['r' if diff < 0 else 'g' for diff in embedding_diff]\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.bar(range(1536), embedding_diff, color=colors, alpha=0.7)\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Embedding Dimension Index')\n",
    "plt.ylabel('Difference in Embedding Values')\n",
    "plt.title('Difference Between the Two Embeddings (Joanne vs Alosh)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Define sentences\n",
    "sentence1 = \"Joanne is a girl\"\n",
    "sentence2 = \"Joanne is a good girl\"\n",
    "\n",
    "# Encode sentences into embeddings\n",
    "embedding1 = model.encode(sentence1)\n",
    "embedding2 = model.encode(sentence2)\n",
    "\n",
    "# Compute the differences between the embeddings\n",
    "embedding_diff = embedding1 - embedding2\n",
    "\n",
    "# Sort the differences by magnitude\n",
    "sorted_indices = np.argsort(np.abs(embedding_diff))[::-1]\n",
    "\n",
    "# Step 1: Visualize the differences\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Step 2: Create a color map: red for negative and green for positive\n",
    "colors = ['r' if embedding_diff[i] < 0 else 'g' for i in sorted_indices]\n",
    "\n",
    "# Step 3: Plot the most significant differences (sorted by absolute magnitude)\n",
    "plt.bar(range(len(sorted_indices)), embedding_diff[sorted_indices], color=colors, alpha=0.7)\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Embedding Dimension Index (sorted by magnitude)')\n",
    "plt.ylabel('Difference in Embedding Values')\n",
    "plt.title('Difference Between Embeddings (\"Joanne is a girl\" vs \"Joanne is a good girl\")')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animating Tokenizer State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Define the sentence and split into words\n",
    "sentence = \"If you're going to write history, you need to know how to read it.\"\n",
    "words = sentence.split()\n",
    "\n",
    "# Generate embeddings for each cumulative sentence\n",
    "embeddings = []\n",
    "for i in range(1, len(words) + 1):\n",
    "    partial_sentence = \" \".join(words[:i])\n",
    "    embedding = model.encode(partial_sentence)\n",
    "    embeddings.append(embedding)\n",
    "\n",
    "# Calculate differences between consecutive embeddings\n",
    "diffs = [embeddings[i] - embeddings[i - 1] for i in range(1, len(embeddings))]\n",
    "\n",
    "# Find global min and max for y-axis scaling\n",
    "global_min = min(np.min(diff) for diff in diffs)\n",
    "global_max = max(np.max(diff) for diff in diffs)\n",
    "\n",
    "sentence = []\n",
    "sentence.append(words[0])\n",
    "\"\".join(sentence)\n",
    "# Create and save individual frames\n",
    "for j, (diff, word) in enumerate(zip(diffs, words[1:])):  # Skip first word\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Sort dimensions by magnitude of change\n",
    "    sorted_indices = np.argsort(np.abs(diff))[::-1]\n",
    "    colors = ['r' if diff[i] < 0 else 'g' for i in sorted_indices]\n",
    "    sentence.append(word)\n",
    "    \"\".join(sentence)\n",
    "    # Create the bar plot\n",
    "    plt.bar(range(len(diff)), diff[sorted_indices], color=colors, alpha=0.7)\n",
    "    plt.xlabel('Embedding Dimension Index (sorted by magnitude)')\n",
    "    plt.ylabel('Difference in Embedding Values')\n",
    "    plt.title(f'{\" \".join(sentence)}')\n",
    "    \n",
    "    # Set consistent y-axis limits for all frames\n",
    "    plt.ylim(global_min, global_max)\n",
    "    \n",
    "    # Save frame with zero-padded index\n",
    "    plt.savefig(f'frame_{j:03d}.png', bbox_inches='tight')\n",
    "    plt.close()  # Important: close the figure to free memory\n",
    "\n",
    "print(f\"Generated {len(diffs)} frames as PNG files with consistent y-axis scaling\")\n",
    "\n",
    "import imageio\n",
    "\n",
    "images = []\n",
    "for j in range(len(diffs)):\n",
    "    images.append(imageio.imread(f'frame_{j:03d}.png'))\n",
    "    os.remove(f'frame_{j:03d}.png')  # Delete the PNG file after reading it\n",
    "imageio.mimsave('tokenizer.gif', images, duration=0.5)\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "Image(filename='tokenizer.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output of GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load GPT-2 model and tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\", token='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')\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", token='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')\n",
    "model.eval()\n",
    "\n",
    "# Function to get hidden states\n",
    "def get_hidden_states(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)  # Get hidden states from all layers\n",
    "    return inputs.input_ids, outputs.hidden_states  # Return tokenized input & hidden states\n",
    "\n",
    "# Streaming input simulation\n",
    "def stream_tokens(text, cache_update_fn):\n",
    "    words = text.split()\n",
    "    cache = None  # Initialize empty cache\n",
    "    for i in range(1, len(words) + 1):\n",
    "        partial_text = \" \".join(words[:i])\n",
    "        token_ids, hidden_states = get_hidden_states(partial_text)\n",
    "        \n",
    "        if cache is None:\n",
    "            cache = hidden_states[-1]  # Use the final layer's hidden state\n",
    "        else:\n",
    "            cache = cache_update_fn(cache, hidden_states[-1])  # Update cache with final layer state\n",
    "        \n",
    "        yield token_ids, cache  # Yield current state for testing\n",
    "\n",
    "# Cache update function using diffusion-like update\n",
    "def diffusion_update(old_cache, new_hidden_state, alpha=0.5):\n",
    "    min_len = min(old_cache.shape[1], new_hidden_state.shape[1])  # Ensure dimensional alignment\n",
    "    diff = new_hidden_state[:, -min_len:] - old_cache[:, -min_len:]  # Compute difference\n",
    "    update = old_cache.clone()\n",
    "    update[:, -min_len:] += alpha * diff  # Apply weighted update\n",
    "    return update\n",
    "\n",
    "# Example test text\n",
    "sample_text = \"If you're going to write history, you need to know how to read it.\"\n",
    "\n",
    "# Function to set the y-axis limits based on the mean and standard deviation of the diff\n",
    "def plot_with_custom_ylimits(diff, j, sample_text, saved_frames):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # We expect diff to be a 2D array (tokens, hidden dimension)\n",
    "    # Flatten it to a 1D array of differences\n",
    "    flat_diff = diff.flatten()\n",
    "\n",
    "    # Step 2: Create a color map: red for negative and green for positive\n",
    "    colors = ['r' if val < 0 else 'g' for val in flat_diff]\n",
    "\n",
    "    # Step 3: Plot the most significant differences (sorted by absolute magnitude)\n",
    "    sorted_indices = np.argsort(np.abs(flat_diff))[::-1]\n",
    "\n",
    "    plt.bar(range(len(sorted_indices)), flat_diff[sorted_indices], color=colors, alpha=0.7)\n",
    "\n",
    "    # Add the sentence as the plot title\n",
    "    partial_sentence = \" \".join(sample_text.split()[:j + 1])  # Current sentence being processed\n",
    "    plt.title(f\"{partial_sentence}\")\n",
    "\n",
    "    # Labels and title\n",
    "    plt.xlabel('Output Dimension Index (sorted by magnitude)')\n",
    "    plt.ylabel('Difference in Output Layer Values')\n",
    "\n",
    "    # Calculate mean and standard deviation for y-axis limits\n",
    "    mean_diff = np.mean(flat_diff)\n",
    "    std_diff = np.std(flat_diff)\n",
    "\n",
    "    # Set the y-axis limits based on mean ± 2 * standard deviation\n",
    "    y_min = mean_diff - 2 * std_diff\n",
    "    y_max = mean_diff + 2 * std_diff\n",
    "\n",
    "    # Apply y-axis limits\n",
    "    plt.ylim(y_min, y_max)\n",
    "    \n",
    "    # Save the frame\n",
    "    frame_filename = f'frame_{j:03d}.png'\n",
    "    plt.savefig(frame_filename, bbox_inches='tight')\n",
    "    plt.close()  # Important: close the figure to free memory\n",
    "\n",
    "    # Add the frame filename to the list\n",
    "    saved_frames.append(frame_filename)\n",
    "\n",
    "# Initialize variables to track global min and max\n",
    "saved_frames = []  # Initialize the list for saving frames\n",
    "cache = None  # Initialize the cache\n",
    "\n",
    "# Single pass to compute diffs\n",
    "for j, (token_ids, updated_cache) in enumerate(stream_tokens(sample_text, diffusion_update)):    \n",
    "    updated_cache = updated_cache.detach().cpu().numpy()\n",
    "\n",
    "    # If cache is still None, initialize it with the first update\n",
    "    if cache is None:\n",
    "        cache = updated_cache\n",
    "        continue  # Skip the diff calculation for the first iteration\n",
    "\n",
    "    diff = updated_cache - cache  # Compute difference between updated cache and previous cache\n",
    "    cache = updated_cache  # Update cache with the new hidden state\n",
    "\n",
    "    # Visualize the differences with dynamic y-axis limits based on mean and standard deviation\n",
    "    plot_with_custom_ylimits(diff, j, sample_text, saved_frames)\n",
    "\n",
    "# Now, create the GIF using the saved frames\n",
    "images = []\n",
    "for frame_filename in saved_frames:\n",
    "    images.append(imageio.imread(frame_filename))  # Read each saved frame\n",
    "    os.remove(frame_filename)  # Delete the frame after reading it\n",
    "\n",
    "# Save the frames as a GIF\n",
    "imageio.mimsave('model.gif', images, duration=0.5)\n",
    "\n",
    "# Display the GIF\n",
    "from IPython.display import Image\n",
    "Image(filename='model.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT2 All Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from PIL import Image as Image\n",
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load GPT-2 model and tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", output_hidden_states=True)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Function to get hidden states from all layers\n",
    "def get_hidden_states(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return inputs.input_ids, outputs.hidden_states  # Return tokenized input & hidden states\n",
    "\n",
    "# Streaming input simulation\n",
    "def stream_tokens(text, cache_update_fn):\n",
    "    words = text.split()\n",
    "    cache = [None] * (model.config.n_layer + 1)  # Initialize cache for all layers (including embeddings)\n",
    "    for i in range(1, len(words) + 1):\n",
    "        partial_text = \" \".join(words[:i])\n",
    "        token_ids, hidden_states = get_hidden_states(partial_text)\n",
    "        \n",
    "        # Update cache for each layer\n",
    "        for layer_idx in range(len(hidden_states)):\n",
    "            if cache[layer_idx] is None:\n",
    "                cache[layer_idx] = hidden_states[layer_idx]  # Initialize cache for the first iteration\n",
    "            else:\n",
    "                cache[layer_idx] = cache_update_fn(cache[layer_idx], hidden_states[layer_idx])  # Update cache\n",
    "        \n",
    "        yield token_ids, cache  # Yield current state for testing\n",
    "\n",
    "# Cache update function using diffusion-like update\n",
    "def diffusion_update(old_cache, new_hidden_state, alpha=0.5):\n",
    "    min_len = min(old_cache.shape[1], new_hidden_state.shape[1])  # Ensure dimensional alignment\n",
    "    diff = new_hidden_state[:, -min_len:] - old_cache[:, -min_len:]  # Compute difference\n",
    "    update = old_cache.clone()\n",
    "    update[:, -min_len:] += alpha * diff  # Apply weighted update\n",
    "    return update\n",
    "\n",
    "# Example test text\n",
    "sample_text = \"If you're going to write history, you need to know how to read it.\"\n",
    "\n",
    "# Function to set the y-axis limits based on the mean and standard deviation of the diff\n",
    "def plot_with_custom_ylimits(diff, j, sample_text, saved_frames, layer_idx, num_layers):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Flatten diff for easier visualization\n",
    "    flat_diff = diff.flatten()\n",
    "\n",
    "    # Create a color map: red for negative and green for positive\n",
    "    colors = ['r' if val < 0 else 'g' for val in flat_diff]\n",
    "\n",
    "    # Sort by absolute magnitude to highlight the most significant differences\n",
    "    # sorted_indices = np.argsort(np.abs(flat_diff))[::-1]\n",
    "\n",
    "    sorted_indices = range(len(flat_diff))  # No sorting, just iterate through all the indices\n",
    "\n",
    "    # Plot the most significant differences\n",
    "    plt.bar(range(len(sorted_indices)), flat_diff[sorted_indices], color=colors, alpha=0.7)\n",
    "\n",
    "    # Add the sentence as the plot title\n",
    "    partial_sentence = \" \".join(sample_text.split()[:j + 1])  # Current sentence being processed\n",
    "    plt.title(f\"Layer {layer_idx}: {partial_sentence}\")\n",
    "\n",
    "    # Labels and title\n",
    "    plt.xlabel('Output Dimension Index (sorted by magnitude)')\n",
    "    plt.ylabel('Difference in Output Layer Values')\n",
    "\n",
    "    # Calculate mean and standard deviation for y-axis limits\n",
    "    mean_diff = np.mean(flat_diff)\n",
    "    std_diff = np.std(flat_diff)\n",
    "\n",
    "    # Set the y-axis limits based on mean ± 2 * standard deviation\n",
    "    y_min = mean_diff - 2 * std_diff\n",
    "    y_max = mean_diff + 2 * std_diff\n",
    "\n",
    "    # Apply y-axis limits\n",
    "    plt.ylim(y_min, y_max)\n",
    "    \n",
    "    # Save the frame\n",
    "    frame_filename = f'frame_{j:03d}_layer_{layer_idx}.png'\n",
    "    plt.savefig(frame_filename, bbox_inches='tight')\n",
    "    plt.close()  # Important: close the figure to free memory\n",
    "\n",
    "    # Add the frame filename to the list\n",
    "    saved_frames[layer_idx].append(frame_filename)\n",
    "\n",
    "# Initialize variables to track global min and max\n",
    "num_layers = model.config.n_layer + 1  # Number of layers (including embeddings)\n",
    "saved_frames = [[] for _ in range(num_layers)]  # Initialize the list for saving frames for each layer\n",
    "cache = [None] * num_layers  # Initialize cache for all layers (including embeddings)\n",
    "\n",
    "# Single pass to compute diffs across all layers\n",
    "for j, (token_ids, updated_cache) in enumerate(stream_tokens(sample_text, diffusion_update)):\n",
    "    # For each layer in the cache, compute the difference and visualize it\n",
    "    for layer_idx, updated_hidden_state in enumerate(updated_cache):\n",
    "        updated_hidden_state = updated_hidden_state.detach().cpu().numpy()\n",
    "\n",
    "        # If cache for this layer is still None, initialize it with the first update\n",
    "        if cache[layer_idx] is None:\n",
    "            cache[layer_idx] = updated_hidden_state\n",
    "            continue  # Skip the diff calculation for the first iteration\n",
    "\n",
    "        diff = updated_hidden_state - cache[layer_idx]  # Compute difference between updated cache and previous cache\n",
    "        cache[layer_idx] = updated_hidden_state  # Update cache with the new hidden state\n",
    "\n",
    "        # Visualize the differences with dynamic y-axis limits based on mean and standard deviation\n",
    "        plot_with_custom_ylimits(diff, j, sample_text, saved_frames, layer_idx, num_layers)\n",
    "\n",
    "# Create individual GIFs for each layer\n",
    "for layer_idx in range(num_layers):\n",
    "    images = []\n",
    "    for frame_filename in saved_frames[layer_idx]:\n",
    "        images.append(imageio.imread(frame_filename))  # Read each saved frame\n",
    "        os.remove(frame_filename)  # Delete the frame after reading it\n",
    "\n",
    "    # Save the frames as a GIF for the current layer\n",
    "    imageio.mimsave(f'layer_{layer_idx + 1}.gif', images, duration=0.5)\n",
    "\n",
    "# Load all GIFs\n",
    "layer_gifs = [imageio.get_reader(f'layer_{i+1}.gif') for i in range(num_layers)]\n",
    "\n",
    "# Get the number of frames (assuming all GIFs have the same number of frames)\n",
    "num_frames = min([gif.get_length() for gif in layer_gifs])\n",
    "\n",
    "# Number of rows and columns for the grid (adjust these based on the number of layers)\n",
    "grid_rows = 4\n",
    "grid_cols = (num_layers + grid_rows - 1) // grid_rows  # Ensure all layers fit in the grid\n",
    "\n",
    "# Create a list to store the combined frames in grid format\n",
    "combined_frames_grid = []\n",
    "\n",
    "for frame_idx in range(num_frames):\n",
    "    frames = [Image.fromarray(gif.get_next_data()) for gif in layer_gifs]  # Extract frames\n",
    "    widths, heights = zip(*(frame.size for frame in frames))  # Get dimensions\n",
    "\n",
    "    # Determine the size of each cell in the grid\n",
    "    max_width = max(widths)\n",
    "    max_height = max(heights)\n",
    "\n",
    "    # Create a blank canvas for the grid (larger enough to hold the grid of images)\n",
    "    total_width = grid_cols * max_width\n",
    "    total_height = grid_rows * max_height\n",
    "    new_frame = Image.new('RGB', (total_width, total_height))\n",
    "\n",
    "    # Place each frame in the grid at the appropriate position\n",
    "    for idx, frame in enumerate(frames):\n",
    "        row = idx // grid_cols  # Determine the row in the grid\n",
    "        col = idx % grid_cols  # Determine the column in the grid\n",
    "\n",
    "        # Calculate position to paste the current frame in the grid\n",
    "        x_offset = col * max_width\n",
    "        y_offset = row * max_height\n",
    "\n",
    "        # Paste the frame at the calculated position\n",
    "        new_frame.paste(frame, (x_offset, y_offset))\n",
    "\n",
    "    combined_frames_grid.append(new_frame)\n",
    "\n",
    "# Save as final GIF\n",
    "output_gif_grid = 'combined_layers_grid.gif'\n",
    "combined_frames_grid[0].save(output_gif_grid, save_all=True, append_images=combined_frames_grid[1:], duration=500, loop=0)\n",
    "\n",
    "# Cleanup individual layer GIFs if needed\n",
    "for i in range(num_layers):\n",
    "    os.remove(f'layer_{i+1}.gif')\n",
    "\n",
    "print(f\"Combined grid GIF saved as {output_gif_grid}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
